{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pylab import mpl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = pd.read_csv('all_sheets_merge_T1 - all_sheets_merge_0430.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "pca = PCA(n_components=10)\n",
    "test3['性別'] = test3['性別'].map({'M':0,'F':1})\n",
    "test3=test3.fillna(0)\n",
    "test3.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in test3.columns.values]\n",
    "X = test3.drop(['呼吸器成功脫離'], axis=1)\n",
    "y = test3['呼吸器成功脫離']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc.fit(X_train, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc.fit(X_train_t, y_train_t)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test_t, y_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 2363)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [2043 2044 2045 2046 2081 2082 2083] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(220, 150)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(f_classif, k=150).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=33)\n",
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 16.        , 49.        , ...,  3.0061357 ,\n",
       "        12.        ,  8.        ],\n",
       "       [ 0.        , 16.        , 25.        , ...,  3.50259163,\n",
       "        22.        , 10.        ],\n",
       "       [ 0.        , 24.        , 53.        , ...,  3.08267416,\n",
       "        11.        , 12.        ],\n",
       "       ...,\n",
       "       [ 0.        , 25.        , 44.        , ...,  0.56568542,\n",
       "        15.        , 10.        ],\n",
       "       [ 0.        ,  9.        , 30.        , ...,  3.10701491,\n",
       "        17.        ,  6.        ],\n",
       "       [ 0.        , 23.        , 40.        , ...,  2.93449314,\n",
       "        20.        , 14.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of eXtreme Gradient Boosting Classifier on testing set: 0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "xgbc.fit(X_train, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5) \n",
    "knn.fit(X_train,y_train)\n",
    "scores = cross_val_score(knn,X,y,cv=10,scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,55)\n",
    "k_scores = []\n",
    "for k_number in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_number)\n",
    "    scores = cross_val_score(knn,X,y,cv=5,scoring='accuracy')\n",
    "    k_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_range,k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pl_log_reg_pca = Pipeline(steps=[('scaler',StandardScaler()), ('pca', PCA(n_components = 5)), ('log_reg', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=200))])\n",
    "scores = cross_val_score(pl_log_reg_pca, test3, label_df, cv=10,scoring='accuracy')\n",
    "print('Accuracy for Logistic Regression with 5 Principal Components: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3=test3.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "pl_xgb = Pipeline(steps= [('xgboost', xgb.XGBClassifier(objective='multi:softmax'))]) \n",
    "scores = cross_val_score(pl_xgb, test3, label_df, cv=10) \n",
    "print('Accuracy for XGBoost Classifier : ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test3[['Age', 'RCC_APACHEII', '氣切', 'Difference APACHEII 6', 'Difference APACHEII 8', 'Difference APACHEII 9', '呼吸器天數', 'RCC天數', '插管-氣切',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test3['呼吸器成功脫離']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = test3.drop(labels=['呼吸器成功脫離'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test3['呼吸器成功脫離']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(xgbc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unnamed: 7 = int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test[['Unnamed: 7', 'Unnamed: 9']]\n",
    "y = test['Unnamed: 19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data_pca = pca.fit_transform(X)\n",
    "model = XGBClassifier(n_estimators=117,max_depth=3)#先实例化一个算法模型，接着去拟合\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=33)\n",
    "over_samples = SMOTE(random_state=12) \n",
    "over_samples_X,over_samples_y = over_samples.fit_sample(X_train, y_train)\n",
    "#over_samples_X, over_samples_y = over_samples.fit_sample(X_train.values,y_train.values.ravel())\n",
    "# 重抽样前的类别比例\n",
    "print(y_train.value_counts()/len(y_train))\n",
    "# 重抽样后的类别比例\n",
    "print(pd.Series(over_samples_y).value_counts()/len(over_samples_y))\n",
    "model.fit(over_samples_X, over_samples_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回模型的预测效果\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for  value in y_pred]#返回浮点数x的四舍五入值\n",
    "accuracy=accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy *100.0))\n",
    "thresholds=sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    selection=SelectFromModel(model,threshold=thresh,prefit=True)#threshold_ ：采用的阈值\n",
    "    #prefit ：布尔，默认为False，是否为训练完的模型,如果是False的话则先fit，再transform\n",
    "    select_X_train=selection.transform(over_samples_X)\n",
    "    selection_model=XGBClassifier()\n",
    "    selection_model.fit(select_X_train,over_samples_y)\n",
    "    ## fit_transform()先拟合数据，再标准化  \n",
    "    #X_train = ss.fit_transform(X_train)  \n",
    "    # transform()数据标准化  \n",
    "    #X_test = ss.transform(X_test) \n",
    "    select_X_test=selection.transform(X_test)\n",
    "    y_pred=selection_model.predict(select_X_test)\n",
    "    predictions=[round(value) for value in y_pred]\n",
    "    accuracy=accuracy_score(y_test,predictions)\n",
    "    print(\"Thresh=%.3f,n=%d,Accuracy:%.2f%%\"%(thresh,select_X_train.shape[1],accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_sheets_merge_T1 - all_sheets_merge_0430.csv')\n",
    "df = df.fillna(0)\n",
    "X = df.drop(['呼吸器成功脫離'], axis=1)\n",
    "y = df['呼吸器成功脫離']\n",
    "X = X.rename(columns={'ICU APACHEII FiO2(<=1)':'ICU APACHEII FiO2', 'RCC APACHEII FiO2(<=1)':'RCC APACHEII FiO2'})\n",
    "X['性別'] = X['性別'].map({'M':0, 'F':1})\n",
    "df = df.fillna(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "xgb = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=117,\n",
    " max_depth=3,\n",
    " min_child_weight=8,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=xgb.predict(X_test)\n",
    "predictions=[round(value) for  value in y_pred]\n",
    "accuracy=accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy *100.0))\n",
    "thresholds=sort(xgb.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    selection=SelectFromModel(xgb,threshold=thresh,prefit=True)\n",
    "    select_X_train=selection.transform(X_train)\n",
    "    selection_model=XGBClassifier()\n",
    "    selection_model.fit(select_X_train,y_train)\n",
    "    ## fit_transform()先拟合数据，再标准化\n",
    "    #X_train = ss.fit_transform(X_train)\n",
    "    #transform()数据标准化\n",
    "    #X_test = ss.transform(X_test) \n",
    "    select_X_test=selection.transform(X_test)\n",
    "    y_pred=selection_model.predict(select_X_test)\n",
    "    predictions=[round(value) for value in y_pred]\n",
    "    accuracy=accuracy_score(y_test,predictions)\n",
    "    print(\"Thresh=%.3f,n=%d,Accuracy:%.2f%%\"%(thresh,select_X_train.shape[1],accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "fig,ax = pyplot.subplots(figsize=(20,20))\n",
    "plot_importance(model,height=0.5,ax=ax,max_num_features=64)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(reduced_data_pca, y)\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
